---
layout: post
title: Ã‰tat des lieux 2025 des modalitÃ©s IA et tendances des JDLS & MIAI Days
tags: [IA, MultimodalitÃ©, Open-Source, JDLS2025, MIAI, Vision, Texte, Audio, 3D, VidÃ©o]
---

Lâ€™intelligence artificielle (IA) a franchi en 2025 un nouveau cap de maturitÃ©, avec des avancÃ©es majeures sur toutes ses modalitÃ©s fondamentalesÂ : texte, image, vidÃ©o, audio et 3D. Tour dâ€™horizon actualisÃ© des articles publiÃ©s sur [angiopteris.github.io](https://angiopteris.github.io/) en 2024, complÃ©tÃ© par les derniÃ¨res Ã©volutions constatÃ©es cette annÃ©e.

En juin s'est tenu la journÃ©e **JDLS 2025** et demain commence **MIAI Days Grenoble**.

---

## Texte : des modÃ¨les de langue ouverts et puissants

Les LLMs open-source ont rattrapÃ©, voire dÃ©passÃ© les modÃ¨les propriÃ©taires. Le modÃ¨le chinois **DeepSeek-R1**, lancÃ© dÃ©but 2025, illustre cette tendance : performance Ã©levÃ©e, coÃ»t dâ€™entraÃ®nement rÃ©duit, dÃ©ploiement open-source. Il rivalise avec GPT-4 tout en Ã©tant tÃ©lÃ©chargeable et exÃ©cutable localement.

Les usages se diversifient : gÃ©nÃ©ration de texte, agents de recherche sur le web, assistants scientifiques, etc. Des interfaces comme **OpenWebUI** permettent mÃªme de crÃ©er un environnement IA localisÃ© avec navigation web, intÃ©gration de modÃ¨les vocaux, ou mÃªme agents de recherche OSINT.

Mistral s'alie Ã  OpenHands afin de dÃ©velopper l'IA agentic.

---

## Image : vers la convergence vision/langage

Lâ€™annÃ©e 2025 marque la montÃ©e en puissance de lâ€™IA multimodale. **Pixtral**, publiÃ© par Mistral, combine vision et langage au sein dâ€™un mÃªme modÃ¨le open-source. Il est capable dâ€™interprÃ©ter des documents, lire des tableaux, ou rÃ©pondre Ã  des questions sur des images complexes.

Des outils locaux comme **ComfyUI** (interface nodale pour la gÃ©nÃ©ration par diffusion) permettent de contrÃ´ler finement les rendus gÃ©nÃ©rÃ©s, et de concevoir des workflows IA totalement personnalisÃ©s en local.

---

## VidÃ©o : la gÃ©nÃ©ration IA se dÃ©mocratise

GrÃ¢ce Ã  la mÃ©thode **FramePack** (proposÃ©e par Lvmin Zhang en 2025), la gÃ©nÃ©ration de vidÃ©os longues devient possible sur GPU modestes (6 Go). Cette technique compacte lâ€™information temporelle, autorisant des rendus fluides et cohÃ©rents, mÃªme pour des clips de 60 secondes.

On assiste Ã  une explosion dâ€™outils open-source intÃ©grant ces approches, rendant possible la crÃ©ation de vidÃ©os stylisÃ©es, animÃ©es, ou illustratives directement depuis un prompt.

---

## Audio : la synthÃ¨se devient mobile

Des modÃ¨les comme **Stable Audio Open Small** (Stability AI) rendent lâ€™IA audio exÃ©cutable sur tÃ©lÃ©phone. CrÃ©ation de loops, effets sonores, fond musical deviennent accessibles sans cloud.

CÃ´tÃ© voix, les modÃ¨les open-source comme **Bark** produisent des voix rÃ©alistes, multilingues et expressives, ouvrant la voie Ã  des applications de doublage, narration ou vocalisation dâ€™agents virtuels.

---

## 3D : les premiers pas de la gÃ©nÃ©ration dâ€™objets et scÃ¨nes

Des plateformes comme **Meshy.ai** permettent aujourdâ€™hui de gÃ©nÃ©rer des modÃ¨les 3D texturÃ©s depuis des descriptions textuelles. Nvidia, avec **LLaMA-Mesh**, explore des reprÃ©sentations de maillage sous forme textuelle, ouvrant la voie Ã  la 3D par LLM. Une nouvelle version de Meshy est sortie, Meshy-5 Preview > Des performances de reconstruction impressionnantes.

Des projets comme **Chat3D** testent lâ€™interfaÃ§age langage -> 3D temps rÃ©el. Lâ€™usage reste technique, mais les progrÃ¨s laissent prÃ©sager une adoption dans la rÃ©alitÃ© augmentÃ©e, le design rapide, ou les jeux vidÃ©o indÃ©pendants. Meshy reste en tÃªte

---

## Conclusion : tendances et Ã©vÃ©nements majeurs

### JDLS 2025 (Paris)

OrganisÃ©e par le CNRS, la JournÃ©e Deep Learning pour la Science (JDLS 2025) a mis en lumiÃ¨re lâ€™usage croissant de lâ€™IA dans des domaines scientifiques variÃ©s : astrophysique, biologie, droit, physique des matÃ©riauxâ€¦ Lâ€™accent a Ã©tÃ© mis sur lâ€™interdisciplinaritÃ© et le besoin de maintenir lâ€™humain dans la boucle pour Ã©viter les biais.

ğŸ‘‰ [https://jdls-2025.sciencesconf.org](https://jdls-2025.sciencesconf.org)

### MIAI Days 2025 (Grenoble)

Tenu les 19-20 juin Ã  Grenoble, lâ€™Ã©vÃ©nement porte sur les perspectives de lâ€™IA dans la recherche, lâ€™industrie, la santÃ© et la culture. Le laboratoir du MIAI prÃ©sente ses avancÃ©es, ses startups partenaires et les grands axes de lâ€™IA durable et explicable. Lâ€™Ã©vÃ©nement confirme le dynamisme de lâ€™Ã©cosystÃ¨me IA alpin.

ğŸ‘‰ [https://miai-cluster.univ-grenoble-alpes.fr](https://miai-cluster.univ-grenoble-alpes.fr)
ğŸ‘‰ [https://miai-cluster.univ-grenoble-alpes.fr](https://miai-cluster.univ-grenoble-alpes.fr/events/miai-days/miai-days-2025-on-june-19-20-2025-1572910.kjsp)

---

En 2025, lâ€™IA devient **multimodale, distribuÃ©e, ouverte et accessible**. Texte, image, vidÃ©o, audio, 3D : toutes les modalitÃ©s convergent vers un Ã©cosystÃ¨me unifiÃ© et personnalisable. Les innovations se multiplient, et les Ã©vÃ©nements scientifiques en tÃ©moignent : **lâ€™IA est un outil transdisciplinaire, collectif et stratÃ©gique**, Ã  la fois instrument de connaissance et sujet dâ€™engagement Ã©thique.